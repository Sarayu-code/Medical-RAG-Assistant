# Choose local LLM or a hosted one (for now we’ll draft with local or any you have)
MODEL_NAME=llama-3.1-8b-instruct  # or "gpt-4o-mini" if you’ll wire via an SDK
EMBEDDINGS_MODEL=all-MiniLM-L6-v2
STORE_DIR=./store
